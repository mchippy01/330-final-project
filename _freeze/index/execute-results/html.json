{
  "hash": "474f518714d9cb4072b84c98cb61ca9f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Ess 330 Final Report \"\nauthors:\n  - name: Chippy Marx\n    affiliation: CSU\n    roles: writing\n    corresponding: true\n  - name: Chris Drew\n    affiliation: CSU\n    roles: writing\n\nbibliography: references.bib\nexecute: \n  echo: true\n---\n\n\n\n\n\n# *Burned and Overrun: Forecasting Colorado’s Invasive Future*\n\n*Invasive plants and wildfires are becoming a growing concern across Colorado, especially as the climate continues to get hotter and drier. In this project, we set out to understand how invasive forbs and grasses might spread in the future—and where they’re most likely to take hold. Using historic field data from the U.S. Forest Service and climate projections under the SSP5-8.5 “worst-case” emissions scenario, we built machine learning models to map areas at highest risk. We combined spatial data, climate variables (like temperature and precipitation), and random forest modeling to predict invasion patterns through mid-century. What we found was that some regions—particularly the Western Slope and the San Juans—are more vulnerable than others, especially in places that already show signs of invasion today. Our results suggest that early warning signs are already visible, and by using tools like predictive modeling, we can better plan where to focus restoration and fire prevention efforts moving forward.*\n\n# Introduction \n\nInvasive plants and wildfires are becoming bigger problems in Colorado. As the climate gets hotter and drier, wildfires are happening more often and in many places, invasive grasses and forbs are moving in right behind them. These plants make it harder for native species to bounce back, and in some cases, they actually make future fires worse by adding more fuel to the landscape @prevey2024non.\n\nSome invasive species are especially good at surviving in stressful conditions, like heat and drought, which gives them an advantage in the changing climate @byun2018management . This creates a dangerous cycle: fire clears the way for invasives, and invasives make future fires more intense. It’s a pattern that’s been seen across the West, but it looks different depending on the region and the type of plants involved.\n\nFor our project, we focused on Colorado. We used future projections from Prevey et al. that estimate how much invasive grass and forb cover might increase under a worst-case climate scenario (SSP5-8.5) @prevey2024non. These projections are based on data from burned sites across the western U.S. and include climate, soil, and topography as predictors @prevey2024non. We also pulled in real field data from the U.S. Forest Service (2006–2007) to ground our models in what’s already happening on the ground.\n\nIn Colorado, the data shows a lot less variation than in other places like the Sierras or Pacific Northwest. That makes it harder to build strong models just from invasion values. So we added a new step: K-means clustering, using climate and invasion variables to group similar environments. This gave us a better sense of where invasives might thrive in the future especially in places that are already showing signs of stress today.\n\nWe compared a total of 10 sites in Colorado spread out geographically. We then visualized the trend of invasive grasses and forbs over time at these 10 sites. We also  applied machine learning models—especially random forest—to predict future invasions under mid-century climate scenarios and highlight areas most vulnerable to future fire-invasion interactions across Colorado.\n\n### Background & Importance \n\nInvasive plant species are an emerging threat in Colorado. They disrupt ecosystems, reduce biodiversity, and weaken the ability of landscapes to recover from stress. Some invasives even change how often and how severely fires occur, creating feedback loops that lead to more frequent wildfires @prevey2024non. \n\nHealthy native plant communities are usually more resistant to invasion. But when ecosystems are already stressed—by drought, disturbance, or heat—non-native species have an easier time spreading @byun2018management. As Colorado gets hotter and drier, these conditions are expected to give invasive grasses and forbs a competitive edge, especially in areas recovering from fire @byun2018management. \n\nWe focused our project on a “worst-case” climate scenario (SSP5-8.5)—a high-emissions pathway that reflects what might happen if countries fail to meet climate goals. With major global players like the U.S. stepping back from emission targets, it's important to understand the ecological risks of staying on our current path. Our goal was to show what invasive spread might look like if climate change continues unchecked. \n\n### Hypothesis\n\n**Visual Trend Hypothesis** \n\nWe expect the greatest increases in invasive grass and forb cover to occur in northwestern Colorado, where the climate is expected to become significantly hotter and drier. These conditions are likely to favor drought-tolerant invasives over native plants. \n\n**Machine Learning Hypothesis** \n\nWe expect maximum temperature and precipitation to be the most important predictors in our machine learning models. As climate stress increases, native species may decline, creating opportunities for invasives that are more adapted to heat, drought, and disturbance \n\n# Methods\n\n**The Data we are using**\n\nWe used four datasets in our project. The first was the projection data from Prevey et al. Wenalso used climateR, developed by Mike Johnson  to retrieve 2015–2020 average climate variables for Colorado, including precipitation (ppt), maximum temperature (tmax), soil moisture, solar radiation (srad), vapor pressure deficit (vpd), and potential evapotranspiration (pet) @climateR2024. The AOI package (also developed by Mike) stands for Area of Interest @AOI2024. It helps users easily define and retrieve spatial boundaries (like states, counties, or custom polygons) as spatial features, which can then be used for cropping rasters or extracting climate data. We used AOI to obtain and transform the boundary for Colorado to match the projection of your raster dataset he getTerraClim() function from the climateR package lets users download high-resolution climate data from the TerraClim dataset @AOI2024. It allows you to choose a location, specific climate variables, and a time range. The usage is the same as what is in the ClimateR because TerraClim is a function from that package @AOI2024.\n\nIn our analysis using the climateR package we chose 6 predictor variables. We chose maximum temperature (tmax), Precipitation (ppt), soil moisture content (soil), vapor pressure deficit (vpd), potential evapotranspiration (pet), and solar radiation (srad).  We chose tmax because it is critical for determining physiological threshold and growing season length @hatfield2015temperature . We chose precipitation because it determines soil moisture and plant productivity @jiang2022precipitation . Soil moisture content was chosen because it influences plant establishment and competition; some invasive species can tolerate drought better or exploit moist soil more effectively than some natives @zhang2020increased . Potential evapotranspiration was chosen because it helps assess water stress conditions, and invasives have been known to exploit these conditions @lu2019various. SRAD was chosen because it influences photosynthesis and growth, correlating with biomass and affecting competition dynamics @zhang2021diffuse. Vapor pressure deficit was chosen because it reflects atmospheric dryness; high VPD stresses plants, reducing native resistance and creating openings for invasives @grossiord2020plant .\n\nThe main limitation in our study was that the projected data that we had showed very little variation in Colorado, as you can see in figure 1 @prevey2024non . This led us to adding climatic data ( from @climateR2024) to create k-means in order to provide our model more variation to predict off of. The reason we used k-means is that models are better at predicting means then a true model when variance in the data is low. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(terra)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nterra 1.8.42\n\nAttaching package: 'terra'\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(dplyr)\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nr = rast(\"/Users/chippymarx/Downloads/sl_forb_current.tiff\") \n#use extract for long and lat \n\nInvasive_data <- read_csv(\"data/CO_INVASIVE_SUBPLOT_SPP.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 3975 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): VEG_FLDSPCD, VEG_SPCD\ndbl  (13): CN, PLT_CN, INVYR, STATECD, UNITCD, COUNTYCD, PLOT, SUBP, CONDID,...\nlgl   (1): MODIFIED_DATE\ndttm  (1): CREATED_DATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nLocation_data <- read_csv(\"data/CO_PLOTGEOM.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 29168 Columns: 24\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): ECOSUBCD, ROADLESSCD, FVS_VARIANT\ndbl  (16): CN, STATECD, INVYR, UNITCD, COUNTYCD, PLOT, LAT, LON, CONGCD, HUC...\nlgl   (3): FVS_DISTRICT, ECO_UNIT_PNW, PRECIPITATION\ndttm  (2): CREATED_DATE, MODIFIED_DATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nInvasive_withLoc <- inner_join(Invasive_data, Location_data, by = c(\"PLT_CN\" = 'CN'))\ncolnames(Invasive_withLoc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"CN\"              \"PLT_CN\"          \"INVYR.x\"         \"STATECD.x\"      \n [5] \"UNITCD.x\"        \"COUNTYCD.x\"      \"PLOT.x\"          \"SUBP\"           \n [9] \"CONDID\"          \"VEG_FLDSPCD\"     \"UNIQUE_SP_NBR\"   \"VEG_SPCD\"       \n[13] \"COVER_PCT\"       \"CREATED_DATE.x\"  \"MODIFIED_DATE.x\" \"CYCLE\"          \n[17] \"SUBCYCLE\"        \"STATECD.y\"       \"INVYR.y\"         \"UNITCD.y\"       \n[21] \"COUNTYCD.y\"      \"PLOT.y\"          \"LAT\"             \"LON\"            \n[25] \"CONGCD\"          \"ECOSUBCD\"        \"HUC\"             \"EMAP_HEX\"       \n[29] \"FIPSCOUNTY\"      \"ROADLESSCD\"      \"CREATED_DATE.y\"  \"MODIFIED_DATE.y\"\n[33] \"ALP_ADFORCD\"     \"FVS_VARIANT\"     \"FVS_LOC_CD\"      \"FVS_REGION\"     \n[37] \"FVS_FOREST\"      \"FVS_DISTRICT\"    \"ECO_UNIT_PNW\"    \"PRECIPITATION\"  \n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nTMP <- Invasive_withLoc %>%\n  select(PLT_CN, LAT, INVYR.x, LON, VEG_FLDSPCD, COVER_PCT) %>%\n  filter(INVYR.x == 2007) %>%                \n  drop_na()  \npts = TMP %>% \n  st_as_sf(coords = c(\"LON\", 'LAT'), remove = FALSE, crs = 4326) %>% \n  distinct()\n\npts$sl_forb_current = extract(r, pts)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: [extract] transforming vector data to the CRS of the raster\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nbb = st_bbox(pts) %>% \n  sf::st_as_sfc() %>% \n  st_as_sf() %>% \n  st_transform(crs(r))\n\ncc = crop(r, bb)\n\n\nplot(cc)\nmtext(\"Figure 1: Projected raster values for current invasive forb coverage cropped to Colorado\", \n      side = 1,       # Bottom of plot\n      line = 4,       # Lines below the axis (adjust as needed)\n      cex = 0.8)  \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n\n\n**Data importing and initial cleaning**\n\nBefore we could do any of our analysis, we had to import our projected spatial data, and extract the raster values from it. The historic invasive species data we had did not have latitude and longitude, which was important for analysis, so we found a dataset that had these values and shared site identifier values. We did an inner-join on these two datasets, and then selected only the attributes we would need for analysis to make the dataset smaller, filtered to the year we were interested in (2007), and removed missing values.  We had to prepare the spatial point data with the extracted raster values by filtering and formatting the dataset so that it was clean. Then, we  transformed the coordinate system of our historic data in order to match that of the raster data , or our projected dataset. Next we extracted the raster values from our projected dataset for the sites we had in our historic data set. We then binded these extracted values with the points in our historic dataset to create a new dataset where each row had both spatial and raster-derived information.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n✔ broom        1.0.8     ✔ rsample      1.3.0\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.8     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.3.0     \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ dials::buffer()   masks terra::buffer()\n✖ scales::discard() masks purrr::discard()\n✖ terra::extract()  masks tidyr::extract()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n✖ recipes::update() masks terra::update(), stats::update()\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(terra)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ranger)\nlibrary(ggplot2)\nlibrary(tidyr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# bring in forb data \nr <- rast(c(\n  \"data/sl_forb_current.tiff\",\n  \"data/sl_forb_mid_585.tiff\",\n  \"data/sl_forb_late_585.tiff\"\n))\n\n#bring in grass data \ng <- rast(c('data/sl_grass_current.tiff','data/sl_grass_late_585.tiff', 'data/sl_grass_mid_585.tiff' ))\n\n\n# Load and join historic  data\nInvasive_data <- read_csv(\"data/CO_INVASIVE_SUBPLOT_SPP.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 3975 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): VEG_FLDSPCD, VEG_SPCD\ndbl  (13): CN, PLT_CN, INVYR, STATECD, UNITCD, COUNTYCD, PLOT, SUBP, CONDID,...\nlgl   (1): MODIFIED_DATE\ndttm  (1): CREATED_DATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nLocation_data <- read_csv(\"data/CO_PLOTGEOM.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 29168 Columns: 24\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): ECOSUBCD, ROADLESSCD, FVS_VARIANT\ndbl  (16): CN, STATECD, INVYR, UNITCD, COUNTYCD, PLOT, LAT, LON, CONGCD, HUC...\nlgl   (3): FVS_DISTRICT, ECO_UNIT_PNW, PRECIPITATION\ndttm  (2): CREATED_DATE, MODIFIED_DATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nInvasive_withLoc <- inner_join(Invasive_data, Location_data, by = c(\"PLT_CN\" = \"CN\"))\n\n# Filter and clean historic data \nTMP <- Invasive_withLoc %>%\n  select(PLT_CN, LAT, INVYR.x, LON, VEG_FLDSPCD, COVER_PCT) %>%\n  filter(INVYR.x == 2007) %>%\n  drop_na()\n\n# Convert the historic data frame into a spatial object using longitude and latitude coordinates.\n# Retain original coordinate columns and set the CRS to WGS84 (EPSG:4326).\npts = TMP %>% \n  st_as_sf(coords = c(\"LON\", 'LAT'), remove = FALSE, crs = 4326) %>% \n  distinct()\n```\n:::\n\n\n\n\n\n*In our analysis we preformed two main tests: one visually analyzing the trend of invasive forb and grass coverage across ten sites of interest, and one unsupervised machine learning model using k-means to predict mid-century invasive forb coverage.*\n\n### **Test 1: Visualizations**\n\nFor this visual test we selected 10 sites from the map, trying to spread out across the state. We then created faceted scatter plots for 10 randomly selected sites of invasive forb and grass cover by three time points: Current, Mid-century (2040–2060), and Late-century (2080–2100) for the SSP585 climate scenario. The plots allowed us to examine visually vegetation cover trends without predictive modeling.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#sites we will select, project\nsite_ids = c(12224885010690, 12221198010690, 12223803010690, 12206792010690, 12222071010690, 1223416010690,\t12225851010690,\t12232600010690, 12212814010690, \t12214073010690  ) \n\n#filer spatial data to only include the 10 sites of interest, then reproject. \nex_pts = pts %>% \n  filter(PLT_CN %in% site_ids) %>% \n  st_transform(crs(r))\n\n#extract raster values and bind comlums \nv <- terra::extract(r, ex_pts)\nex_Pts_both = bind_cols(ex_pts, v)\n\nex_pts_g = pts %>% \n  filter(PLT_CN %in% site_ids) %>% \n  st_transform(crs(g))\n\ng <-  terra::extract(g, ex_pts_g)\nex_Pts_both_g = bind_cols(ex_pts_g, g)\n#do the same for grass data \n\n\n\n\nex_pts = pts %>% \n  filter(PLT_CN %in% site_ids) %>% \n  #distinct() %>% \n  st_transform(crs(r))\n\nv <-  terra::extract(r, ex_pts)\nex_Pts_both = bind_cols(ex_pts, v)\n\n#point of this is ... for forb \ndf_long <- ex_Pts_both %>%\n  select(ID, COVER_PCT, sl_forb_current, sl_forb_mid_585, sl_forb_late_585) %>%\n  pivot_longer(\n    cols = c(COVER_PCT, sl_forb_current, sl_forb_mid_585, sl_forb_late_585),\n    names_to = \"variable\",\n    values_to = \"value\"\n  )\n\n#for grass \ndf_long_g <- ex_Pts_both_g %>%\n  select(ID, COVER_PCT, sl_grass_current, sl_grass_mid_585, sl_grass_late_585) %>%\n  pivot_longer(\n    cols = c(COVER_PCT, sl_grass_current, sl_grass_mid_585, sl_grass_late_585),\n    names_to = \"variable\",\n    values_to = \"value\"\n  )\n```\n:::\n\n\n\n\n\n*Plot Forbs*\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Filter to 10 unique IDs\nten_ids_forb <- df_long %>% \n  distinct(ID) %>%\n  slice_head(n = 10) %>%\n  pull(ID)\n\ndf_subset_forb <- df_long %>%\n  filter(ID %in% ten_ids_forb)\n\n# Convert ID to factor to preserve facet order\ndf_subset_forb$ID <- factor(df_subset_forb$ID)\n\ndf_subset_forb <- df_subset_forb %>%\n  mutate(\n    variable = recode(variable,\n      \"COVER_PCT\" = \"2007 (Observed)\",\n      \"sl_forb_current\" = \"Current (1981–2010)\",\n      \"sl_forb_mid_585\" = \"Mid-century (2041–2070)\",\n      \"sl_forb_late_585\" = \"Late-century (2071–2100)\"\n    ),\n    scenario_label = case_when(\n      variable == \"2007 (Observed)\" ~ \"2007\",\n      variable == \"Current (1981–2010)\" ~ \"Current\",\n      variable == \"Mid-century (2041–2070)\" ~ \"Mid-century\",\n      variable == \"Late-century (2071–2100)\" ~ \"Late-century\",\n      TRUE ~ NA_character_  # catch unmatched cases\n    ),\n    scenario_label = factor(scenario_label, levels = c(\"2007\", \"Current\", \"Mid-century\", \"Late-century\"))\n  ) %>%\n  filter(!is.na(scenario_label))  # drop rows with NA scenario_label\n\n# Plot\nForb_vis <- ggplot(df_subset_forb, aes(x = scenario_label, y = value, group = ID)) +\n  geom_line(aes(color = variable), linewidth = 1) +\n  geom_point(size = 2) +\n  facet_wrap(~ ID, scales = \"fixed\", nrow = 2) +\n  labs(\n    x = \"Scenario\",\n    y = \"Cover Percentage\",\n    title = \"Forb Cover Change by Site (10 Sample IDs)\",\n    color = \"Scenario Timeframe\",\n    caption = \"Figure 2. Invasive Forb Coverage over time at our 10 Sites of interest\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(size = 16, face = \"bold\"),\n    plot.title = element_text(hjust = 0.5)\n  )\nprint(Forb_vis)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n\n*Plot Grasses*\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Filter to 10 unique IDs\nten_ids <- df_long_g %>% \n  distinct(ID) %>%\n  slice_head(n = 10) %>%\n  pull(ID)\n\ndf_subset <- df_long_g %>%\n  filter(ID %in% ten_ids)\n\n# Convert ID to factor to control facet order and labels\ndf_subset$ID <- factor(df_subset$ID)\n\ndf_subset_grass <- df_subset %>%\n  mutate(\n    # Detailed labels for the legend\n    variable = recode(variable,\n      \"COVER_PCT\" = \"2007 (Observed)\",\n      \"sl_grass_current\" = \"Current (1981–2010)\",\n      \"sl_grass_mid_585\" = \"Mid-century (2041–2070)\",\n      \"sl_grass_late_585\" = \"Late-century (2071–2100)\"\n    ),\n    # Simplified x-axis labels\n    scenario_label = case_when(\n      variable == \"2007 (Observed)\" ~ \"2007\",\n      variable == \"Current (1981–2010)\" ~ \"Current\",\n      variable == \"Mid-century (2041–2070)\" ~ \"Mid-century\",\n      variable == \"Late-century (2071–2100)\" ~ \"Late-century\",\n      TRUE ~ NA_character_\n    ),\n    # Ensure factor order on x-axis\n    scenario_label = factor(scenario_label, levels = c(\"2007\", \"Current\", \"Mid-century\", \"Late-century\"))\n  ) %>%\n  filter(!is.na(scenario_label))  # remove any unmatched\n\n# Plot\nggplot(df_subset_grass, aes(x = scenario_label, y = value, group = ID)) +\n  geom_line(aes(color = variable), linewidth = 1) +\n  geom_point(size = 2) +\n  facet_wrap(~ ID, scales = \"fixed\", nrow = 2) +\n  labs(\n    x = \"Scenario\",\n    y = \"Cover Percentage\",\n    title = \"Grass Cover Change by Site (10 Sample IDs)\",\n    color = \"Scenario Timeframe\",\n    caption = \"Figure 3. Invasive grass coverage over time at our 10 Sites of interest\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(size = 16, face = \"bold\"),\n    plot.title = element_text(hjust = 0.5)\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\n**Building the reference map**\n\nFor these figures we wanted to create a reference map of where the 10 sites we chose were. To do this we laid our 10 sites (using their lat and long values) on a map of Colorado. Next, we added the labels of the sites to the data set. We had to transform the location values back to lat and lon as we had projected them in the coordinate system of our spatial data earlier. We then plotted this onto our map of Colorado.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Get US state boundaries from base R maps\nusa <- map_data(\"state\")\n\n# Filter for Colorado\ncolorado <- usa %>% filter(region == \"colorado\")\n\n# Step 1: Add labels BEFORE converting to lat/lon\nex_pts$Label <- as.character(1:nrow(ex_pts))\n\n# Step 2: Transform to lat/lon and extract coordinates\nex_pts_latlon <- st_transform(ex_pts, crs = 4326) %>% \n  mutate(\n    lon = st_coordinates(.)[, 1],\n    lat = st_coordinates(.)[, 2]\n  ) %>%\n  st_drop_geometry()\n\n# Step 3: Group overlapping points and combine labels\nex_pts_latlon_grouped <- ex_pts_latlon %>%\n  group_by(lon, lat) %>%\n  summarise(Label = paste0(\"Site \", paste(Label, collapse = \" & \")), .groups = \"drop\")\n\n# Step 4: Plot\nggplot() +\n  geom_polygon(data = colorado, aes(x = long, y = lat, group = group),\n               fill = \"lightgreen\", color = \"grey\") +\n  geom_point(data = ex_pts_latlon_grouped, aes(x = lon, y = lat), color = \"darkgreen\", size = 3) +\n  geom_text(data = ex_pts_latlon_grouped, aes(x = lon, y = lat, label = Label), \n            nudge_y = 0.2, size = 5) +\n  coord_fixed(1.3) +\n  labs(title = \"Sites of interest in Colorado\",\n       x = \"Longitude\", y = \"Latitude\",\n       caption = \"Figure 4. Reference map of 10 sites of interest \") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    axis.text = element_blank(),\n    axis.ticks = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Test 2: Unsupervised machine learning model using k-means.\n\nFirst we got the state boundary for Colorado from the AOI package @AOI2024 and projected it to the same coordinate reference system. We cropped all of the raster data to Colorado, then extracted all the raster values, removing all rows with missing data. \n\nThen we scaled the data with mean=1 and standard deviation=0 . This is important for K-means because it creates equal weighting of variables on different scales, and fair distance computation.  K-means uses euclidean distance, which is sensitive to scale, so scaling ensures all variables contribute equally to the clustering.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(terra)      \nlibrary(sf)          \nlibrary(tidyverse)   \nlibrary(tidymodels)  \nlibrary(remotes)\n\nlibrary(AOI)\n\nlibrary(climateR)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'climateR'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:readr':\n\n    parse_date\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:graphics':\n\n    plot\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:base':\n\n    plot\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Set the coordinate reference system (CRS) from an existing raster\ncrs = crs(rast(\"data/sl_forb_current.tiff\"))\n\n# Get the state boundary for Colorado and project \nco = AOI::aoi_get(state = \"CO\") |> \n  sf::st_transform(crs)\n\n# Load two raster layers and crop them to Colorado\nr = terra::rast(c('data/sl_forb_current.tiff',\n                  'data/sl_grass_current.tiff')) |> \n  terra::crop(co)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Load mid-century projections (future climate scenario) and crop them\nr2 = terra::rast(c('data/sl_forb_mid_585.tiff',\n                   'data/sl_grass_mid_585.tiff')) |> \n  terra::crop(co)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Extract all current raster values\nv = values(r)\n\n# Identify non-NA rows\nidx <- which(!apply(is.na(v), 1, any))\n\n# Remove rows with NA values\nv   <- na.omit(v)\n\n# Scale the data (mean = 0, sd = 1)\nvs  <- scale(v)\n```\n:::\n\n\n\n\n\n We then performed K-means clustering**,** setting the maximum number of iterations the algorithm will run to refine the cluster assignments to 100. It is important to set a maximum  to avoid infinite loops in case convergence is slow**.** We randomly set the k-mean to 5. K-mean is a clustering algorithm used in unsupervised machine learning  to group data points into a specified number of clusters, based on similarity. Smaller K-means simplify the iteration, and avoid overfitting, but can lead to missing important subgroup differences; we did not worry about this in our study because the raster/projection data had very little variance to begin with.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nE <- kmeans(vs, 5, iter.max = 100)\n\nclus_raster <- r[[1]]\nvalues(clus_raster) <- NA\nclus_raster[idx] <- E$cluster\n```\n:::\n\n\n\n\n\nNext we created a new raster for the cluster results, and mapped that. Next we combined the current and future forb predictions and the cluster rasters into a single stack; this builds a multi-layer raster stack for future analysis. This step is key for linking cluster ID's to present and future landscape characteristics.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nset.seed(123)\n\nplot(clus_raster, col = RColorBrewer::brewer.pal(5, \"Spectral\"))\nmtext(\"Figure 5: Clustered raster values for invasive forb coverage mid century\", \n      side = 1, line = 4, cex = 0.8)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\n# Combine current, future, and cluster rasters into a single stack\nrs = c(r, r2, cl = clus_raster) |> \n  setNames(c(names(r), names(r2), \"cluster\"))\n```\n:::\n\n\n\n\n\nNext we defined the climate variables we would use in creating our rasters.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nparams = c('tmax', \"soil\", \"srad\", \"ppt\", \"vpd\", \"pet\")\n```\n:::\n\n\n\n\n\nNext, using the TerraCLim package (from @climateR2024) , setting the dates between 2015 and 2020, we binded that data to the raster data, extracting gM and mean. We split that bound data into training and testing sets, set a seed, and created  10-fold cross-validation splits. We then defined our 6 models, defined our recipe, normalizing all predictors and removing unwanted columns. We then tested each model with the metrics of root mean squared error (RMSE) and R2.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Download TerraClim climate data for Colorado (2015–2020 average)\ngM = climateR::getTerraClim(co, params, \n                            startDate = \"2015-01-01\", \n                            endDate   = \"2020-12-31\") \n\n\n# Load field plot data (data from 2007) and join with plot geometries\npts <- inner_join(read_csv(\"data/CO_INVASIVE_SUBPLOT_SPP.csv\"), \n                  read_csv(\"data/CO_PLOTGEOM.csv\"), \n                  by = c(\"PLT_CN\" = 'CN')) %>% \n  st_as_sf(coords = c(\"LON\", 'LAT'), crs = 4326) |> \n  st_transform(crs)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 3975 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): VEG_FLDSPCD, VEG_SPCD\ndbl  (13): CN, PLT_CN, INVYR, STATECD, UNITCD, COUNTYCD, PLOT, SUBP, CONDID,...\nlgl   (1): MODIFIED_DATE\ndttm  (1): CREATED_DATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 29168 Columns: 24\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): ECOSUBCD, ROADLESSCD, FVS_VARIANT\ndbl  (16): CN, STATECD, INVYR, UNITCD, COUNTYCD, PLOT, LAT, LON, CONGCD, HUC...\nlgl   (3): FVS_DISTRICT, ECO_UNIT_PNW, PRECIPITATION\ndttm  (2): CREATED_DATE, MODIFIED_DATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Extract raster and climate data to points\nxx = bind_cols(\n  terra::extract(rs, pts),  \n  terra::extract(rast(map(gM, mean)), pts)[,-1]\n) |> \n  drop_na()\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: [extract] transforming vector data to the CRS of the raster\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nwrite_csv(xx, \"data/xx.csv\")\n#saves the cleaned, extracted data to a CSV file \n# Split data into training and testing sets, stratified by cluster\nxx = read_csv(\"data/xx.csv\") \n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 3965 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): ID, sl_forb_current, sl_grass_current, sl_forb_mid_585, sl_grass_m...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nxx = replace(xx, xx == 0 , 1)\n\n\n#set seed and do inital split \nset.seed(123)\ns = initial_split(xx, strata = cluster)\ntraining = training(s)\ntesting = testing(s)\n\n# Create 10-fold cross-validation splits\nfolds = vfold_cv(training, v = 10)\n\n# Define various models\nlm_mod = linear_reg() |> \n  set_engine(\"lm\") |> \n  set_mode(\"regression\")\n\nb_mod = boost_tree() |> \n  set_engine(\"xgboost\") |> \n  set_mode(\"regression\")\n\nb_mod2 = boost_tree() |> \n  set_engine(\"lightgbm\") |> \n  set_mode(\"regression\")\n\nrf_mod = rand_forest() |> \n  set_engine(\"ranger\", importance = \"impurity\") |> \n  set_mode(\"regression\")\n\nnn_mod = mlp() |> \n  set_engine(\"nnet\") |> \n  set_mode(\"regression\")\n\nlibrary(bonsai)  \n\n# Build a recipe to preprocess the data \nrec = recipe(sl_forb_mid_585 ~ ., data = training) |> \n  step_rm(sl_grass_mid_585, ID) |> \n  step_normalize(all_predictors())\n\n# Create a workflow set: recipe + all models\nwf = workflow_set(list(rec),\n                  list(lm_mod, \n                       xgboost = b_mod, \n                       lightgbm = b_mod2, \n                       nn_mod, \n                       rf_mod))  |> \n  workflow_map(resamples = folds)\n\n# Visualize workflow performance\nautoplot(wf) + \n  labs(caption = \"Figure 6: Canidate models' preformence visualized for comparison\" )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\n# Collect model evaluation metrics\ncollect_metrics(wf) |> \n  filter(.metric == \"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 9\n  wflow_id          .config preproc model .metric .estimator  mean     n std_err\n  <chr>             <chr>   <chr>   <chr> <chr>   <chr>      <dbl> <int>   <dbl>\n1 recipe_linear_reg Prepro… recipe  line… rmse    standard   0.914    10  0.0172\n2 recipe_xgboost    Prepro… recipe  boos… rmse    standard   0.454    10  0.0214\n3 recipe_lightgbm   Prepro… recipe  boos… rmse    standard   0.381    10  0.0226\n4 recipe_mlp        Prepro… recipe  mlp   rmse    standard   0.772    10  0.0206\n5 recipe_rand_fore… Prepro… recipe  rand… rmse    standard   0.326    10  0.0220\n```\n\n\n:::\n:::\n\n\n\n\n\nOur results showed that the random forest model performed the best with a RMSE of 0.259 and a R2 value of 0.954 (figure 6).  We fit the random forest model to the training data, and tuned the hyperparameters of mtry, trees, and min_n. Mtry was tuned because it controls the number of predictor variables selected at each split; high mtry reduces the randomness of the model. We tuned trees as it controls the number of decision trees; more trees means better performance to a point, but slower training. We tuned min_n which controls the number of data points a node must have to be split further; higher values create underfitting, and lower creates overfitting.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Build a single workflow with random forest model\nwf = workflow() |> \n  add_recipe(rec) |> \n  add_model(rf_mod) \n\n# Fit the random forest to training data\nwf_f = wf |> \n  fit(data = training) \n\n# Visualize feature importance \nvip::vip(wf_f) +\n  labs(caption = \"Figure 7: Variable importance for final model\") +\n  theme(plot.caption = element_text(hjust = 0.5, size = 10))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\n# Tune hyperparameters of random forest\nrf_t = rand_forest(trees = tune(), \n                   mtry = tune(), \n                   min_n = tune()) |> \n  set_engine(\"ranger\") |> \n  set_mode(\"regression\")\n```\n:::\n\n\n\n\n\nWe then performed a grid search to find the best combination of hyperparameters,and then finalized the workflow with the best hyperparameter. Next we did a final fit on the test set, collecting the rsq metric. We then visualized the importance of the vvaribles in our model for predicting mid century invasive forb coverage (figure 7). Finally we predicted on all of our data, and visualted the predictions across clusters.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntg = tune_grid(rf_t, \n               preprocessor = rec,\n               resamples = folds, \n               grid = 25)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Show best performing hyperparameter set based on metric of choice. I chose R2\nshow_best(tg, metric = \"rsq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     6  1167     2 rsq     standard   0.950    10 0.00629 Preprocessor1_Model17\n2     3   667     3 rsq     standard   0.947    10 0.00667 Preprocessor1_Model08\n3     7   417     6 rsq     standard   0.947    10 0.00641 Preprocessor1_Model20\n4     5  1833     8 rsq     standard   0.944    10 0.00646 Preprocessor1_Model13\n5     8  1666     9 rsq     standard   0.943    10 0.00650 Preprocessor1_Model22\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Finalize workflow with best hyperparameters\nworkflow <- finalize_workflow(wf,  \n                              select_best(tg, metric = \"rsq\"))\n\n# Final fit on test set\n(final_fit <- last_fit(workflow, s))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits             id               .metrics .notes   .predictions .workflow \n  <list>             <chr>            <list>   <list>   <list>       <list>    \n1 <split [2973/992]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Collect evaluation metrics on test set\ncollect_metrics(final_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       0.224 Preprocessor1_Model1\n2 rsq     standard       0.965 Preprocessor1_Model1\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Plot predicted vs observed values (test set)\ncollect_predictions(final_fit) |> \n  ggplot(aes(x = .pred, y = sl_forb_mid_585 )) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  geom_abline(slope = 1, intercept = 0) +\n  theme_bw() +\n  labs(x = \"Predicted\", y = \"Observed\",\n       caption = \"Figure 8. Observed vs. Predicted values \") +\n  coord_equal()\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\n# Fit model to all data\nmod = fit(workflow, xx)\n\n# Visualize predictions across clusters\naugment(mod, new_data = xx) |> \n  ggplot(aes(x = .pred, y = sl_forb_mid_585, color = as.factor(cluster))) +\n  scale_color_brewer(palette = \"Spectral\") +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0) +\n  theme_bw() +\n  labs(x = \"Predicted\", y = \"Observed\",\n       caption = \"Figure 9. Obeserved vs. Predicted values by clusters \") +\n  coord_equal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n\n\n\n\n\n# Results\n\n### Visual test\n\nThe visualizations provide an initial look into how forb and grass cover may shift under the projected climate scenario (SSP585). Forb cover showed considerable variation across the 10 selected sites when comparing the “Current,” “Mid-century,” and “Late-century” projections. Some sites exhibited clear declines in forb cover over time, while others maintained relatively stable levels or showed modest increases (figure 2).\n\nGrass cover showed a more consistent trend across sites. Most sites experienced a decline in grass cover across the three time periods (figure 3). The one notable exception was the most westerly site, which displayed stability or a slight increase in grass cover under future climate projections.\n\n### Unsupervised machine learning model using k-means.\n\nOur final model had a root mean square error of 0.259, and an R-squared value of 0.968. We saw that the three most important variables in predicting invasive forb coverage were current invasive forb coverage, current invasive grass coverage and precipitation; with maximum temperature being the least important (figure 7). We saw that in general, the model was better at predicting higher values, as the clusters #4 and #5 are closer to the regression line of predicted versus actual values (figures 8 & 9). Higher values are clustered more towards the western part of the state, in general (figures 5 & 9).\n\n# Discussion\n\nThe analysis of our data relies heavily on climatic and topographic maps of Colorado. This is because our model was unsupervised, meaning that we were unable to retrieve or see the data that each cluster was pulling from. We will therefore analyze and discuss our results geographically and based on climatic maps .\n\n![Figure 10. Topographic map of Colorado from YellowMaps used for analyisis](images/TopoCO.png){width=\"468\"}\n\n[![Figure 11. Colorado 2021 temperatures compared to historic ranges from WestWide Drought Tracker](images/COtemp.png)](https://wrcc.dri.edu/wwdt/about.php)\n\n[![Figure 12. Colorado 2021 precipitation compared to historic ranges from WestWide Drought Tracker](images/PrecipCO.png)](https://wrcc.dri.edu/wwdt/about.php)\n\n### Test 1: Visual\n\nOur initial visual observations suggest that both forb and grass cover can be significantly affected by projected late-century climate conditions. However, the response of these plant functional groups appears to vary by site and group.\n\n**Site-Level Trends and Implications**\n\nForbs showed very variable patterns at sites. For example, some eastern slope sites had sharp forb declines, while others—those with unique microclimates or at higher elevations—had stable or even increasing forb cover (figures 2 and 10). This diversity suggests that forb response to climate change potentially can be strongly site-specific, with localized environmental factors, species assemblages, or interactions not captured by large-scale climate variables being the decisive factors.\n\nIn contrast, grass cover also decreased in a more uniform manner at most locations, particularly on the east-facing slope (figure 3). Such homogeneity could be a sign of a broader sensitivity of grasses to the imposed changes in temperature and precipitation regimes. The only exception was the site farthest west, where grass cover was more stable or even slightly increasing, highlighting the importance of geographic and climatic context for controlling vegetation response. We see that the western slope of the state is experiencing hotter and drier condition (figures 11 & 12), and think that these conditons may favor invasives that are more accustomed to hotter and drier conditons, or those that can exploit moisture in direr conditons.\n\n### Test 2: Unsupervised machine learning model using k-means.\n\nThe two most important variables in predicting invasive forb coverage mid century were current coverage of invasive forbs and grasses (figure 7) . This is likely because these invasives are already present and taking hold. The presence of them in the area means they can disperse more easily into other nearby areas, and can start their process of dominance. The reason that invasive grass coverage was important in predicting future forb coverage is likely because these ecosystems are already disturbed, reducing their resilience and making them more susceptible to future invasions. \n\nAnnual precipitation was the third most important variable in predicting future forb coverage. This makes sense, because as discussed in the methods section, precipitation  determines soil moisture and plant productivity @jiang2022precipitation. Because we ran an unsupervised model, we cannot see the underlying data that the clusters are pulling from. Therefor, we cannot be sure if high or low precipitation is associated with higher invasive coverage. However, looking at climate maps such as figure 12, we can deduce that because the higher forb coverage clusters are generally in the west, lower than average precipitation is associated with higher invasive coverage. While temperature did not prove to be very important in our model, based on figure 11, we see that in the west there have also been higher than average temperatures. These two conditions combined lead us to believe that Western Colorado is more susceptible to invasive forbs than Eastern Colorado due to the dramatically changing climatic conditions in the region. \n\nAnother trend that we saw by looking at the cluster map and predicted vs. actual graph (figures 5 & 9 ) and a topographic map of Colorado (figure 10) is that the two clusters with highest values are valleys. We believe this is because valleys rely on runoff from the mountains, in this case the Western Slope. If those areas do not receive as much precipitation, the valleys do not receive runoff and are water stressed.\n\n# Conclusions and Next steps\n\nIn both of our tests, we can see that areas expected to experience more prominent effects of climate change are more at risk for invasive plants in the future. This underscores the importance of avoiding 585 “worst case” climate scenarios. Policy needs to be enforced and participated in globally that will prevent the emissions that would lead to this climate scenario. We know that invasive species are only one of the risks under this scenario, and maybe not even the most pressing, but they will further degrade these vulnerable ecosystems, and could lead to disruptions in disturbance regimes such as fire and disease.\n\nIf we had more time for this study, we would have several next steps. We would like to look into the connection between unprecedented forest fires in Colorado to see if these fires could be a predicting factor in invasive coverage. We would also like to test other disturbances such as historic fire suppression, urban sprawl,and disease to see if these could be trained into the model. \n\nWe believe that further research needs to be done to analyze the functional groups discussed in this study, as well as specific invasives. Researchers still need to figure out how  invaders interact with things like competition from native plants or environmental conditions @byun2018management. This would provide insight into why these invaders are so successful, which could be used to inform management decisions. \n\nUltimately , our study shows the importance of avoiding worst case scenario climate scenarios, identifying new and creative  ways to stop the spread and dominance of invasive species, and restoring native vegetation communities and ecosystems. Restoration will be an important part of our path forward in stopping invasive species dominance, as we know that healthy ecosystems do not foster invasive species, as their niches are full and functioning well @byun2018management.  \n\n\\\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}