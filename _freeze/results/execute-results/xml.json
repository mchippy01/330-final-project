{
  "hash": "d2976ca54abbc705e5dd3a094178a16c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Ess 330 Project Updates\" \n\nauthors:\n  - name: Chippy Marx\n    affiliation: CSU\n    roles: writing\n    corresponding: true\n  - name: Chris Drew\n    affiliation: CSU\n    roles: writing\n\nbibliography: references.bib\nexecute: \n  echo: true\n---\n\n\n\n\n\n\n\n\n# Methods\n\n**Data importing and initial cleaning**\n\nBefore we could do any of our analysis, we had to import our projected spatial data, and extract the raster values from it. The historic invasive species data we had did not have latitude and longitude, which was important for  analysis, so we found a dataset that had these values and shared site identifier values. We did an inner-join on these two datasets, and then selected only the attributes we would need for analysis to make the dataset smaller, filtered to the year we were interested in (2007), and removed missing values.  We had to prepare the spatial point data with the extracted raster values by filtering and formatting the dataset so that it was clean. Then, we  transformed the coordinate system of our historic data in order to match that of the raster data , or our projected dataset. Next we extracted the raster values from our projected dataset for the sites we had in our historic data set. We then binded these extracted values with the points in our historic dataset to create a new dataset where each row had both spatial and raster-derived information.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(terra)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nterra 1.8.42\n\nAttaching package: 'terra'\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(dplyr)\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(ranger)\nlibrary(ggplot2)\nlibrary(tidyr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# bring in forb data \nr <- rast(c(\n  \"data/sl_forb_current.tiff\",\n  \"data/sl_forb_mid_585.tiff\",\n  \"data/sl_forb_late_585.tiff\"\n))\n\n#bring in grass data \ng <- rast(c('data/sl_grass_current.tiff','data/sl_grass_late_585.tiff', 'data/sl_grass_mid_585.tiff' ))\n\n\n# Load and join historic  data\nInvasive_data <- read_csv(\"data/CO_INVASIVE_SUBPLOT_SPP.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 3975 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): VEG_FLDSPCD, VEG_SPCD\ndbl  (13): CN, PLT_CN, INVYR, STATECD, UNITCD, COUNTYCD, PLOT, SUBP, CONDID,...\nlgl   (1): MODIFIED_DATE\ndttm  (1): CREATED_DATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nLocation_data <- read_csv(\"data/CO_PLOTGEOM.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 29168 Columns: 24\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): ECOSUBCD, ROADLESSCD, FVS_VARIANT\ndbl  (16): CN, STATECD, INVYR, UNITCD, COUNTYCD, PLOT, LAT, LON, CONGCD, HUC...\nlgl   (3): FVS_DISTRICT, ECO_UNIT_PNW, PRECIPITATION\ndttm  (2): CREATED_DATE, MODIFIED_DATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nInvasive_withLoc <- inner_join(Invasive_data, Location_data, by = c(\"PLT_CN\" = \"CN\"))\n\n# Filter and clean historic data \nTMP <- Invasive_withLoc %>%\n  select(PLT_CN, LAT, INVYR.x, LON, VEG_FLDSPCD, COVER_PCT) %>%\n  filter(INVYR.x == 2007) %>%\n  drop_na()\n\n# Convert the historic data frame into a spatial object using longitude and latitude coordinates.\n# Retain original coordinate columns and set the CRS to WGS84 (EPSG:4326).\npts = TMP %>% \n  st_as_sf(coords = c(\"LON\", 'LAT'), remove = FALSE, crs = 4326) %>% \n  distinct()\n```\n:::\n\n\n\n\n\n\n\n\n**Test 1: Visualizations**\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#sites we will select, project\nsite_ids = c(12224885010690, 12221198010690, 12223803010690, 12206792010690, 12222071010690, 1223416010690,\t12225851010690,\t12232600010690, 12212814010690, \t12214073010690  ) \n\n#filer spatial data to only include the 10 sites of interest, then reproject. \nex_pts = pts %>% \n  filter(PLT_CN %in% site_ids) %>% \n  st_transform(crs(r))\n\n#extract raster values and bind comlums \nv <-  extract(r, ex_pts)\nex_Pts_both = bind_cols(ex_pts, v)\n\n#do the same for grass data \nex_pts_g = pts %>% \n  filter(PLT_CN %in% site_ids) %>% \n  st_transform(crs(g))\n\ng <-  extract(g, ex_pts_g)\nex_Pts_both_g = bind_cols(ex_pts_g, g)\n\nex_pts = pts %>% \n  filter(PLT_CN %in% site_ids) %>% \n  #distinct() %>% \n  st_transform(crs(r))\n\nv <-  extract(r, ex_pts)\nex_Pts_both = bind_cols(ex_pts, v)\n\n#point of this is ... for forb \ndf_long <- ex_Pts_both %>%\n  select(ID, COVER_PCT, sl_forb_current, sl_forb_mid_585, sl_forb_late_585) %>%\n  pivot_longer(\n    cols = c(COVER_PCT, sl_forb_current, sl_forb_mid_585, sl_forb_late_585),\n    names_to = \"variable\",\n    values_to = \"value\"\n  )\n\n#for grass \ndf_long_g <- ex_Pts_both_g %>%\n  select(ID, COVER_PCT, sl_grass_current, sl_grass_mid_585, sl_grass_late_585) %>%\n  pivot_longer(\n    cols = c(COVER_PCT, sl_grass_current, sl_grass_mid_585, sl_grass_late_585),\n    names_to = \"variable\",\n    values_to = \"value\"\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Filter to 10 unique IDs\nten_ids_forb <- df_long %>% \n  distinct(ID) %>%\n  slice_head(n = 10) %>%\n  pull(ID)\n\ndf_subset_forb <- df_long %>%\n  filter(ID %in% ten_ids_forb)\n\n# Convert ID to factor to preserve facet order\ndf_subset_forb$ID <- factor(df_subset_forb$ID)\n\ndf_subset_forb <- df_subset_forb %>%\n  mutate(\n    variable = recode(variable,\n      \"COVER_PCT\" = \"2007 (Observed)\",\n      \"sl_forb_current\" = \"Current (1981–2010)\",\n      \"sl_forb_mid_585\" = \"Mid-century (2041–2070)\",\n      \"sl_forb_late_585\" = \"Late-century (2071–2100)\"\n    ),\n    scenario_label = case_when(\n      variable == \"2007 (Observed)\" ~ \"2007\",\n      variable == \"Current (1981–2010)\" ~ \"Current\",\n      variable == \"Mid-century (2041–2070)\" ~ \"Mid-century\",\n      variable == \"Late-century (2071–2100)\" ~ \"Late-century\",\n      TRUE ~ NA_character_  # catch unmatched cases\n    ),\n    scenario_label = factor(scenario_label, levels = c(\"2007\", \"Current\", \"Mid-century\", \"Late-century\"))\n  ) %>%\n  filter(!is.na(scenario_label))  # drop rows with NA scenario_label\n\n# Plot\nggplot(df_subset_forb, aes(x = scenario_label, y = value, group = ID)) +\n  geom_line(aes(color = variable), linewidth = 1) +\n  geom_point(size = 2) +\n  facet_wrap(~ ID, scales = \"fixed\", nrow = 2) +\n  labs(\n    x = \"Scenario\",\n    y = \"Cover Percentage\",\n    title = \"Forb Cover Change by Site (10 Sample IDs)\",\n    color = \"Scenario Timeframe\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(size = 16, face = \"bold\"),\n    plot.title = element_text(hjust = 0.5)\n  )\n```\n\n::: {.cell-output-display}\n![](results_files/figure-jats/unnamed-chunk-4-1.png)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Filter to 10 unique IDs\nten_ids <- df_long_g %>% \n  distinct(ID) %>%\n  slice_head(n = 10) %>%\n  pull(ID)\n\ndf_subset <- df_long_g %>%\n  filter(ID %in% ten_ids)\n\n# Convert ID to factor to control facet order and labels\ndf_subset$ID <- factor(df_subset$ID)\n\ndf_subset_grass <- df_subset %>%\n  mutate(\n    # Detailed labels for the legend\n    variable = recode(variable,\n      \"COVER_PCT\" = \"2007 (Observed)\",\n      \"sl_grass_current\" = \"Current (1981–2010)\",\n      \"sl_grass_mid_585\" = \"Mid-century (2041–2070)\",\n      \"sl_grass_late_585\" = \"Late-century (2071–2100)\"\n    ),\n    # Simplified x-axis labels\n    scenario_label = case_when(\n      variable == \"2007 (Observed)\" ~ \"2007\",\n      variable == \"Current (1981–2010)\" ~ \"Current\",\n      variable == \"Mid-century (2041–2070)\" ~ \"Mid-century\",\n      variable == \"Late-century (2071–2100)\" ~ \"Late-century\",\n      TRUE ~ NA_character_\n    ),\n    # Ensure factor order on x-axis\n    scenario_label = factor(scenario_label, levels = c(\"2007\", \"Current\", \"Mid-century\", \"Late-century\"))\n  ) %>%\n  filter(!is.na(scenario_label))  # remove any unmatched\n\n# Plot\nggplot(df_subset_grass, aes(x = scenario_label, y = value, group = ID)) +\n  geom_line(aes(color = variable), linewidth = 1) +\n  geom_point(size = 2) +\n  facet_wrap(~ ID, scales = \"fixed\", nrow = 2) +\n  labs(\n    x = \"Scenario\",\n    y = \"Cover Percentage\",\n    title = \"Grass Cover Change by Site (10 Sample IDs)\",\n    color = \"Scenario Timeframe\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(size = 16, face = \"bold\"),\n    plot.title = element_text(hjust = 0.5)\n  )\n```\n\n::: {.cell-output-display}\n![](results_files/figure-jats/unnamed-chunk-5-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n**Building the reference map**\n\nFor these figures we wanted to create a reference map of where the 10 sites we chose were. To do this we laid our 10 sites (using their lat and long values) on a map of Colorado. Next, we added the labels of the sites to the data set. We had to transform the location values back to lat and lon as we had projected them in the coordinate system of our spatial data earlier. We then plotted this onto our map of Colorado.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Get US state boundaries from base R maps\nusa <- map_data(\"state\")\n\n# Filter for Colorado\ncolorado <- usa %>% filter(region == \"colorado\")\n\n# Step 1: Add labels BEFORE converting to lat/lon\nex_pts$Label <- as.character(1:nrow(ex_pts))\n\n# Step 2: Transform to lat/lon and extract coordinates\nex_pts_latlon <- st_transform(ex_pts, crs = 4326) %>% \n  mutate(\n    lon = st_coordinates(.)[, 1],\n    lat = st_coordinates(.)[, 2]\n  ) %>%\n  st_drop_geometry()\n\n# Step 3: Group overlapping points and combine labels\nex_pts_latlon_grouped <- ex_pts_latlon %>%\n  group_by(lon, lat) %>%\n  summarise(Label = paste0(\"Site \", paste(Label, collapse = \" & \")), .groups = \"drop\")\n\n# Step 4: Plot\nggplot() +\n  geom_polygon(data = colorado, aes(x = long, y = lat, group = group),\n               fill = \"lightgreen\", color = \"grey\") +\n  geom_point(data = ex_pts_latlon_grouped, aes(x = lon, y = lat), color = \"darkgreen\", size = 3) +\n  geom_text(data = ex_pts_latlon_grouped, aes(x = lon, y = lat, label = Label), \n            nudge_y = 0.2, size = 5) +\n  coord_fixed(1.3) +\n  labs(title = \"Monitoring Sites in Colorado\", subtitle = \"Sites labeled 1–10 (merged if overlapping)\",\n       x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    axis.text = element_blank(),\n    axis.ticks = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](results_files/figure-jats/unnamed-chunk-6-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n**Test 2: Machine Learning**\n\nThe second test we are doing  is a machine learning model in order to train a model to predict the percent cover of invasive forbs in the projected late century (2080–2100) cover data  from our historic cover data, the projected “current” cover (1981-2010), and the projected mid-century cover (2040–2060).  While we are not done with this model, we have taken several steps so far. \n\n When we cleaned this dataset and created our combined historic and projected datasets for the machine learning, to ensure useful group-level analysis, we grouped the data by the classification in the late century dataset, counted the number of observations in each group, and filtered the data to retain only groups with more than 2 observations. We did this because models do not like to predict values that only occur once in the dataset. After ungrouping the data, we prepared it for modeling by converting the cover percentages in both the historic and projected data to factor type, as we saw that classification engines in the models worked better. \n\nNext, we set a seed, did the initial split on our data, and set resamples for modeling. We had to drop the geometry in our dataset, as the models we chose do not support spatial data. We then defined our recipe as described above. \n\nWe chose 3 candidate models: random forest (RF)(with a ranger engine), Xgboost (Xgb) (with a xgboost engine), and a multilayer perceptron (MLP)  (with a neural network engine) model. For all of these models, the mode was set at classification because our data, while numeric values, is categorical not continuous.  We chose the RF model because it handles missing data and outliers well. We chose the Xgb model because it is one of the best models in predictive taste, especially for structured data. We chose the MLP model because it can model complex, nonlinear patterns between predictors and outcomes, and it was suggested to us because of the nature of our data . For each model we defined a workflow.  Next, we defined our list of models for comparison, and set the comparison metrics as Kappa and Accuracy. Accuracy measures the proportion of correctly classified observations out of all observations, and Kappa is a  measure of agreement between the predicted and actual classifications, adjusted for chance agreement (the level of agreement between predicted and actual classifications that would be expected just by random guessing).\n\nWe then got stuck with our analysis, as we need to do more data manipulation and model adjustments before we can run out models. The next steps include making a workflow set with all the models, fitting the workflows with cross-validation, and comparing the models based on our comparison metrics. Once we know which model performs best, we can pick a model, tune that model, find the best hyperparameters, and finalize the workflow, getting predictions. \n\nWe do not know if we have chosen appropriate methods for this analysis yet, as we cannot see any performance metrics until we work out the kinks in our dataset and machine learning methods. \n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nex_pts_Ml = pts %>% \n  st_transform(crs(r))\n\nv2<-  extract(r, ex_pts_Ml)\n\nex_Pts_ml_both <- bind_cols(ex_pts_Ml, v2) %>% \n  group_by(sl_forb_late_585) %>% \n  mutate(n = n()) %>% \n  ungroup() %>% \n  filter(n > 2) %>% \n  mutate(\n    sl_forb_current = as.factor(sl_forb_current),\n    sl_forb_mid_585 = as.factor(sl_forb_mid_585),\n    sl_forb_late_585 = as.factor(sl_forb_late_585),  \n    COVER_PCT = as.factor(COVER_PCT)\n  ) \n\nex_Pts_ml_both$sl_forb_late_585 %>% table()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n.\n 0  1  2  3  4 \n15 68 27 13  4 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#set seed, split data\nset.seed(32)\nex_pts_both_split <- initial_split(ex_Pts_ml_both, prop = 0.8, strata = sl_forb_late_585)\nex_pts_train <- training(ex_pts_both_split)\nex_pts_test  <- testing(ex_pts_both_split)\n\n#resamples \nex_both_cv <- vfold_cv(ex_pts_train, v=10)\n\n#more cleaning \nex_Pts_ml_df <- ex_Pts_ml_both %>%\n  st_drop_geometry()\n\n# Then define your recipe\nforb_recipe <- recipe(sl_forb_late_585 ~ sl_forb_mid_585 + sl_forb_current + COVER_PCT, data = ex_Pts_ml_df) %>%\n  step_naomit(all_predictors(), all_outcomes()) %>%\n  step_normalize(all_numeric_predictors())\n\ntable(ex_Pts_ml_df$sl_forb_late_585)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n 0  1  2  3  4 \n15 68 27 13  4 \n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#prep and bake \nprep(forb_recipe) %>% bake(new_data = NULL)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 127 × 4\n   sl_forb_mid_585 sl_forb_current COVER_PCT sl_forb_late_585\n   <fct>           <fct>           <fct>     <fct>           \n 1 1               2               2         2               \n 2 0               0               2         0               \n 3 2               2               2         1               \n 4 1               1               2         1               \n 5 1               1               2         1               \n 6 1               1               2         1               \n 7 1               1               2         1               \n 8 1               1               2         1               \n 9 1               3               2         1               \n10 1               3               2         1               \n# ℹ 117 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#define 3 candidate models and set workflows \n\nrf_mod <- rand_forest(trees = 500, mtry = 2) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n\nrf_wf <- workflow() %>%\n  add_model(rf_mod) %>%\n  add_recipe(forb_recipe)\n\nxgb_mod <- boost_tree(trees = 500, learn_rate = 0.1) %>%\n  set_engine(\"xgboost\") %>%\n  set_mode(\"classification\")\n\nxgb_wf <- workflow() %>%\n  add_model(xgb_mod) %>%\n  add_recipe(forb_recipe)\n\nnn_mod <- mlp()%>%\n  set_engine(\"nnet\")%>%\n  set_mode(\"classification\")\n\nnn_wf <- workflow() %>% \n  add_model(nn_mod) %>% \n  add_recipe(forb_recipe)\n```\n:::\n\n\n\n\n\n\n\n\n**Where we get stuck**\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#define list of models for comparison \n#model_list <- list(\n # MLP= nn_mod,\n  #random_forest = rf_mod,\n  #xgboost = xgb_mod\n#)\n\n#define my metrics \n#my_metrics <- metric_set\n\n#create workflow set with all models \n#wf_set <- workflow_set(\n # preproc = list(forb = forb_recipe),\n # models = model_list\n#)\n#fit all worklows with cross-validation \n#wf_results <- wf_set %>%\n  #workflow_map(resamples = ex_both_cv, metrics = my_metrics, verbose = TRUE)\n\n#next we would autoplot but this is where we got stuck after meeting with Mike and changing things around. \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#specify tunable parameters \n#xgb_mod_tuned <- boost_tree(\n  #trees = tune(),\n  #learn_rate = tune(),\n  #tree_depth = tune()\n#) %>%\n  #set_engine(\"xgboost\") %>%\n  #set_mode(\"classification\")\n\n#create new workflow \n#xgb_wf_tuned <- workflow() %>%\n  #add_model(xgb_mod_tuned) %>%\n  #add_recipe(forb_recipe)\n\n#define tunable grid\n#xgb_grid <- grid_regular(\n  #trees(range = c(100, 1000)),\n  #learn_rate(range = c(0.01, 0.3)),\n  #tree_depth(range = c(2, 10)),\n  #levels = 5\n#)\n#tune model with cross-validation\n#xgb_tuned_results <- tune_grid(\n  #xgb_wf_tuned,\n  #resamples = ex_both_cv,\n  #grid = xgb_grid,\n  #metrics = my_metrics,\n  #control = control_grid(save_pred = TRUE)\n#)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#evaluate and select the best model \n#best_xgb <- select_best(xgb_tuned_results, metric = \"accuracy\")\n\n#show_best(xgb_tuned_results)\n\n#autoplot(xgb_tuned_results)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#finalize workflow with the best hyperparameters \n#final_xgb_wf <- finalize_workflow(xgb_wf_tuned, best_xgb)\n\n#final model veriication \n#final_xgb_last <- last_fit(\n  #final_xgb_wf,\n  #split = ex_pts_both_split\n#)\n# Collect performance metrics\n#collect_metrics(final_xgb_last)\n#collect predictions \n#final_xgb_preds <- collect_predictions(final_xgb_last)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#names(final_xgb_preds)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#ggplot(final_xgb_preds, aes(x = .pred, y = sl_forb_late_585)) +\n  #geom_point(alpha = 0.6, color = \"steelblue\") +\n  #geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n  #labs(\n    #x = \"Predicted\",\n   # y = \"Actual\",\n  #  title = \"Predicted vs. Actual - Final XGBoost Model\"\n # ) +\n # theme_minimal()\n```\n:::\n\n\n\n\n\n\n\n\n# Results \n\n# Discussion \n",
    "supporting": [
      "results_files/figure-jats"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}